{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heroin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "KY = pd.read_excel(\"Data/KY_Heroin.xlsx\")\n",
    "OH = pd.read_excel(\"Data/OH_Heroin.xlsx\")\n",
    "PA = pd.read_excel(\"Data/PA_Heroin.xlsx\")\n",
    "VA = pd.read_excel(\"Data/VA_Heroin.xlsx\")\n",
    "WV = pd.read_excel(\"Data/WV_Heroin.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.236453201970443\n",
      "14.473451327433628\n",
      "14.008298755186722\n",
      "17.515151515151516\n",
      "14.774774774774775\n",
      "13.82258064516129\n",
      "12.613861386138614\n",
      "8.585106382978724\n"
     ]
    }
   ],
   "source": [
    "for i in range(2010,2018):\n",
    "    print(WV.loc[WV['YYYY'] == i]['DrugReports'].sum() / len(WV.loc[WV['YYYY'] == i]['DrugReports']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "KY_result = KY_Heroin.groupby(\"COUNTY\").sum()['DrugReports'] / KY_Heroin.groupby(\"COUNTY\").count()['DrugReports']\n",
    "OH_result = OH_Heroin.groupby(\"COUNTY\").sum()['DrugReports'] / OH_Heroin.groupby(\"COUNTY\").count()['DrugReports']\n",
    "PA_result = PA_Heroin.groupby(\"COUNTY\").sum()['DrugReports'] / PA_Heroin.groupby(\"COUNTY\").count()['DrugReports']\n",
    "VA_result = VA_Heroin.groupby(\"COUNTY\").sum()['DrugReports'] / VA_Heroin.groupby(\"COUNTY\").count()['DrugReports']\n",
    "WV_result = WV_Heroin.groupby(\"COUNTY\").sum()['DrugReports'] / WV_Heroin.groupby(\"COUNTY\").count()['DrugReports']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = list('K ' + KY_result.index) + list('O ' + OH_result.index) + list('P ' + PA_result.index) + list('V ' + VA_result.index) + list('W ' + WV_result.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "mean = [0.,0.,0.,0.,0.];\n",
    "for i in range(len(KY_result)):\n",
    "    data.append(KY_result[i])\n",
    "    mean[0] += float(KY_result[i])\n",
    "mean[0] /= len(KY_result)\n",
    "\n",
    "for i in range(len(OH_result)):\n",
    "    data.append(OH_result[i])\n",
    "    mean[1] += float(OH_result[i])   \n",
    "mean[1] /= len(OH_result)\n",
    "\n",
    "for i in range(len(PA_result)):\n",
    "    data.append(PA_result[i])\n",
    "    mean[2] += float(PA_result[i])\n",
    "mean[2] /= len(PA_result)\n",
    "\n",
    "for i in range(len(VA_result)):\n",
    "    data.append(VA_result[i])\n",
    "    mean[3] += float(VA_result[i])\n",
    "mean[3] /= len(VA_result)\n",
    "\n",
    "for i in range(len(WV_result)):\n",
    "    data.append(WV_result[i])\n",
    "    mean[4] += float(WV_result[i])\n",
    "mean[4] /= len(WV_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "KY_result = np.array(KY_result).reshape(-1,1)\n",
    "OH_result = np.array(OH_result).reshape(-1,1)\n",
    "PA_result = np.array(PA_result).reshape(-1,1)\n",
    "VA_result = np.array(VA_result).reshape(-1,1)\n",
    "WV_result = np.array(WV_result).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机森林（KY州）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K SHELBY']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=1) # n_estimators是分类器个数，迭代参数，max_depth是树的最大深度，防止过拟合\n",
    "clf.fit(data,label)\n",
    "print(clf.predict(mean[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机森林（OH州）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O LORAIN']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=1) # n_estimators是分类器个数，迭代参数，max_depth是树的最大深度，防止过拟合\n",
    "clf.fit(data,label)\n",
    "test = clf.predict(mean[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O GUERNSEY']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=1) # n_estimators是分类器个数，迭代参数，max_depth是树的最大深度，防止过拟合\n",
    "clf.fit(data,label)\n",
    "test = clf.predict(mean[1])\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机森林（PA州）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P NORTHAMPTON']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=1) # n_estimators是分类器个数，默认10，迭代参数，max_depth是树的最大深度，防止过拟合\n",
    "clf.fit(data,label)\n",
    "print(clf.predict(mean[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机森林（VA州）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V NELSON']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=1) # n_estimators是分类器个数，迭代参数，max_depth是树的最大深度，防止过拟合\n",
    "clf.fit(data,label)\n",
    "print(clf.predict(mean[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机森林（WV州）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W MARSHALL']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=1) # n_estimators是分类器个数，迭代参数，max_depth是树的最大深度，防止过拟合\n",
    "clf.fit(data,label)\n",
    "print(clf.predict(mean[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络（KY州）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K BOONE']\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(1))\n",
    "clf.fit(data,label)\n",
    "print(clf.predict(mean[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络（OH州）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O CUYAHOGA']\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(1))\n",
    "clf.fit(data,label)\n",
    "print(clf.predict(mean[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络（PA州）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P PHILADELPHIA']\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(1))\n",
    "clf.fit(data,label)\n",
    "print(clf.predict(mean[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络（VA州）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V BLAND']\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs',hidden_layer_sizes=(1))\n",
    "clf.fit(data,label)\n",
    "print(clf.predict(mean[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络（WV州）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W TUCKER']\n",
      "['P BEAVER']\n",
      "['W ROANE']\n",
      "['W RANDOLPH']\n",
      "['V NORTHUMBERLAND']\n",
      "['O HAMILTON']\n",
      "['P NORTHAMPTON']\n",
      "['K KENTON']\n",
      "['K MONTGOMERY']\n",
      "['P SNYDER']\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs',hidden_layer_sizes=(1))\n",
    "clf.fit(data,label)\n",
    "print(clf.predict(mean[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合成类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "KY = pd.read_excel(\"Data/KY合成类.xlsx\")\n",
    "OH = pd.read_excel(\"Data/OH合成类.xlsx\")\n",
    "PA = pd.read_excel(\"Data/PA合成类.xlsx\")\n",
    "VA = pd.read_excel(\"Data/VA合成类.xlsx\")\n",
    "WV = pd.read_excel(\"Data/WV合成类.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2962962962962963\n",
      "2.727272727272727\n",
      "3.2\n",
      "3.4285714285714284\n",
      "4.055555555555555\n",
      "7.392156862745098\n",
      "6.955882352941177\n",
      "6.08955223880597\n"
     ]
    }
   ],
   "source": [
    "for i in range(2010,2018):\n",
    "    print(WV.loc[WV['YYYY'] == i]['DrugReports'].sum() / len(WV.loc[WV['YYYY'] == i]['DrugReports']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "649591"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KY_result.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "OH_result = OH.groupby(\"COUNTY\").sum()['TotalDrugReportsCounty'] / OH.groupby(\"COUNTY\").count()['TotalDrugReportsCounty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "PA_result = PA.groupby(\"COUNTY\").sum()['TotalDrugReportsCounty'] / PA.groupby(\"COUNTY\").count()['TotalDrugReportsCounty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "VA_result = VA.groupby(\"COUNTY\").sum()['TotalDrugReportsCounty'] / VA.groupby(\"COUNTY\").count()['TotalDrugReportsCounty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "WV_result = WV.groupby(\"COUNTY\").sum()['TotalDrugReportsCounty'] / WV.groupby(\"COUNTY\").count()['TotalDrugReportsCounty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = list('K ' + KY_result.index) + list('O ' + OH_result.index) + list('P ' + PA_result.index) + list('V ' + VA_result.index) + list('W ' + WV_result.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "mean = [0.,0.,0.,0.,0.];\n",
    "for i in range(len(KY_result)):\n",
    "    data.append(KY_result[i])\n",
    "    mean[0] += float(KY_result[i])\n",
    "mean[0] /= len(KY_result)\n",
    "\n",
    "for i in range(len(OH_result)):\n",
    "    data.append(OH_result[i])\n",
    "    mean[1] += float(OH_result[i])   \n",
    "mean[1] /= len(OH_result)\n",
    "\n",
    "for i in range(len(PA_result)):\n",
    "    data.append(PA_result[i])\n",
    "    mean[2] += float(PA_result[i])\n",
    "mean[2] /= len(PA_result)\n",
    "\n",
    "for i in range(len(VA_result)):\n",
    "    data.append(VA_result[i])\n",
    "    mean[3] += float(VA_result[i])\n",
    "mean[3] /= len(VA_result)\n",
    "\n",
    "for i in range(len(WV_result)):\n",
    "    data.append(WV_result[i])\n",
    "    mean[4] += float(WV_result[i])\n",
    "mean[4] /= len(WV_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理县标签，改为州"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_State = list([0]) * len(KY_result) + list([1]) * len(OH_result) + list([2]) * len(PA_result) + list([3]) * len(VA_result) + list([4]) * len(WV_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 取各个州的县数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KY: 118\n",
      "OH: 88\n",
      "PA: 67\n",
      "VA: 126\n",
      "WV: 53\n"
     ]
    }
   ],
   "source": [
    "print(\"KY:\",len(KY_result))\n",
    "print(\"OH:\",len(OH_result))\n",
    "print(\"PA:\",len(PA_result))\n",
    "print(\"VA:\",len(VA_result))\n",
    "print(\"WV:\",len(WV_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 取所有样本中位数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182.2924836601307\n"
     ]
    }
   ],
   "source": [
    "print(np.median(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 取所有样本均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean = np.sum(data) / len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一维数据转二维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data).reshape(452,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,100):\n",
    "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(i,1), random_state=1)\n",
    "    clf.fit(data,label_State)\n",
    "    print(clf.predict(mean[4]))\n",
    "# OH,KY,WV,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络预测均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['V RICHMOND'], dtype='<U23')"
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(data_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到的结果是[3]，也就是属于VA州"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机森林分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[0]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[0]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[0]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5,100): # i从5到999进行递增\n",
    "    clf = RandomForestClassifier(n_estimators=i,max_depth=5) # n_estimators是分类器个数，迭代参数，max_depth是树的最大深度，防止过拟合\n",
    "    clf.fit(data,label_State)\n",
    "    print(clf.predict(mean[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN模型分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,452):\n",
    "    model = SVC(gamma='scale') # 可以适当调参\n",
    "    model.fit(data,label_State)\n",
    "    print(model.predict(data_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN预测均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array(mean).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p']\n",
      "['p']\n",
      "['o']\n",
      "['k']\n",
      "['k']\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,6):\n",
    "    model = KNN(n_neighbors=i) # 可以适当调参\n",
    "    model.fit(mean,['k','o','p','v','w'])\n",
    "    print(model.predict(data_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K从1取到5的时候，结果分别为上面的值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 朴素贝叶斯分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = MultinomialNB()\n",
    "y_pred =gnb.fit(mean,['k','o','p','v','w'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 贝叶斯预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['k'], dtype='<U1')"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.predict(data_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
